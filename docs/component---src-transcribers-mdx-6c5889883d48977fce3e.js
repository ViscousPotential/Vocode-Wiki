(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{uFsZ:function(e,t,a){"use strict";a.r(t),a.d(t,"_frontmatter",(function(){return s})),a.d(t,"default",(function(){return m}));var l=a("Fcif"),r=a("dV/x"),b=(a("mXGw"),a("/FXl")),n=a("TjRS"),c=a("5hvn");a("aD51");const o=["components"],s={};void 0!==s&&s&&s===Object(s)&&Object.isExtensible(s)&&!Object.prototype.hasOwnProperty.call(s,"__filemeta")&&Object.defineProperty(s,"__filemeta",{configurable:!0,value:{name:"_frontmatter",filename:"src/transcribers.mdx"}});const i={_frontmatter:s},p=n.a;function m(e){let{components:t}=e,a=Object(r.a)(e,o);return Object(b.b)(p,Object(l.a)({},i,a,{components:t,mdxType:"MDXLayout"}),Object(b.b)("h1",{id:"transcribers"},"Transcribers"),Object(b.b)("p",null,"This list should grow as new voice recognition solutions are released."),Object(b.b)("h2",{id:"whisper"},"Whisper"),Object(b.b)(c.b,{size:"small",style:{backgroundColor:"#065F46"},mdxType:"Tag"},"100% offline"),Object(b.b)(c.b,{size:"small",style:{marginLeft:10,backgroundColor:"#3F6212"},mdxType:"Tag"},"fast"),Object(b.b)(c.b,{size:"small",style:{marginLeft:10,backgroundColor:"#3F6212"},mdxType:"Tag"},"accurate"),Object(b.b)("p",null,"Based on the ",Object(b.b)("a",{parentName:"p",href:"https://github.com/openai/whisper"},"Whisper")," project."),Object(b.b)("ul",null,Object(b.b)("li",{parentName:"ul"},"Relatively fast"),Object(b.b)("li",{parentName:"ul"},"Relatively accurate"),Object(b.b)("li",{parentName:"ul"},"100% offline and on-device")),Object(b.b)("h2",{id:"vosk"},"Vosk"),Object(b.b)(c.b,{size:"small",style:{backgroundColor:"#065F46"},mdxType:"Tag"},"100% offline"),Object(b.b)(c.b,{size:"small",style:{marginLeft:10,backgroundColor:"#92400E"},mdxType:"Tag"},"slower"),Object(b.b)(c.b,{size:"small",style:{marginLeft:10,backgroundColor:"#3F6212"},mdxType:"Tag"},"accurate"),Object(b.b)("p",null,"Based on the ",Object(b.b)("a",{parentName:"p",href:"https://github.com/alphacep/vosk-api"},"Vosk")," project"),Object(b.b)("ul",null,Object(b.b)("li",{parentName:"ul"},"Relatively slower"),Object(b.b)("li",{parentName:"ul"},"Relatively accurate"),Object(b.b)("li",{parentName:"ul"},"100% offline and on-device")),Object(b.b)("h2",{id:"faster-whisper"},"Faster Whisper"),Object(b.b)(c.b,{size:"small",style:{backgroundColor:"#065F46"},mdxType:"Tag"},"100% offline"),Object(b.b)(c.b,{size:"small",style:{marginLeft:10,backgroundColor:"#065F46"},mdxType:"Tag"},"faster"),Object(b.b)(c.b,{size:"small",style:{marginLeft:10,backgroundColor:"#3F6212"},mdxType:"Tag"},"less accurate"),Object(b.b)("p",null,"Based on the ",Object(b.b)("a",{parentName:"p",href:"https://github.com/SYSTRAN/faster-whisper"},"Faster-Whisper")," project "),Object(b.b)("ul",null,Object(b.b)("li",{parentName:"ul"},"Relatively faster"),Object(b.b)("li",{parentName:"ul"},"Relatively less accurate"),Object(b.b)("li",{parentName:"ul"},"100% offline and on-device")))}void 0!==m&&m&&m===Object(m)&&Object.isExtensible(m)&&!Object.prototype.hasOwnProperty.call(m,"__filemeta")&&Object.defineProperty(m,"__filemeta",{configurable:!0,value:{name:"MDXContent",filename:"src/transcribers.mdx"}}),m.isMDXComponent=!0}}]);
//# sourceMappingURL=component---src-transcribers-mdx-6c5889883d48977fce3e.js.map